{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Clusters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import altair as alt\n",
    "import gbm\n",
    "import vine\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pdpilot import partial_dependence\n",
    "\n",
    "from clustering import create_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.data_transformers.enable(\"vegafusion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"results\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_instances = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_dataset(num_instances=num_instances, seed=seed)\n",
    "df.to_csv(output_dir / \"data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df.drop(columns=[\"y\"])\n",
    "features = list(df_X.columns)\n",
    "X = df_X.to_numpy()\n",
    "y = df[\"y\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter(df):\n",
    "    df_vis = df.copy()\n",
    "    df_vis[\"cluster\"] = (df_vis[\"x3\"] >= 0) & (df_vis[\"x4\"] >= (1 / 3))\n",
    "    return (\n",
    "        alt.Chart(df_vis)\n",
    "        .mark_point(filled=True)\n",
    "        .encode(\n",
    "            x=\"x2\",\n",
    "            y=\"y\",\n",
    "            color=alt.Color(\"cluster\")\n",
    "            .scale(range=[\"#1b9e77\", \"#7570b3\"])\n",
    "            .legend(title=\"x3 >= 0 and x4 >= 1/3\", orient=\"top\", symbolOpacity=1),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_feature_scatter = scatter(df)\n",
    "x2_feature_scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_feature_scatter.save((output_dir / \"x2-feature-scatter.png\").as_posix(), ppi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes about 90 seconds to run on my M1 Macbook Pro.\n",
    "cv_results, booster = gbm.nested_cross_validation_and_train(\n",
    "    X,\n",
    "    y,\n",
    "    features=features,\n",
    "    nominal_features=[],\n",
    "    objective=\"regression\",\n",
    "    jobs=4,\n",
    "    seed=seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster.save_model(output_dir / \"model.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results[\"scores\"] = cv_results[\"scores\"].to_json(orient=\"records\")\n",
    "(output_dir / \"cv_results.json\").write_text(\n",
    "    json.dumps(cv_results, indent=4), encoding=\"UTF-8\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"CV RMSE: {cv_results['mean_score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the final model has reasonable performance on unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model_performance(booster):\n",
    "    df_eval = create_dataset(num_instances=num_instances, seed=seed + 1)\n",
    "    df_eval_X = df_eval.drop(columns=[\"y\"])\n",
    "    y_eval = df_eval[\"y\"].to_numpy()\n",
    "    y_pred = booster.predict(df_eval_X)\n",
    "\n",
    "    print(f\"MAE: {np.mean(np.abs(y_eval - y_pred))}\")\n",
    "    print(f\"RMSE: {np.mean((y_eval - y_pred) ** 2)}\")\n",
    "\n",
    "    df_plot = pd.DataFrame({\"y_eval\": y_eval, \"y_pred\": y_pred})\n",
    "\n",
    "    min_v = min(y_eval.min(), y_pred.min())\n",
    "    max_v = max(y_eval.max(), y_pred.max())\n",
    "\n",
    "    return (\n",
    "        alt.Chart(df_plot)\n",
    "        .mark_point()\n",
    "        .encode(\n",
    "            x=alt.X(\"y_pred\").scale(domain=[min_v, max_v], nice=True),\n",
    "            y=alt.Y(\"y_eval\").scale(domain=[min_v, max_v], nice=True),\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "check_model_performance(booster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate ICE plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of points in a PDP/ICE line\n",
    "resolution = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDPilot\n",
    "\n",
    "First we have PDPilot use its default parameters for the decision trees, which have a max depth of 3.\n",
    "\n",
    "We use PDPilot to calculate the ICE plots and clusters twice. First, we use its default parameters for the decision trees, which have a max depth of 3. Then we have PDPilot use decision trees with a max depth of 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for decision_tree_params in [{\"max_depth\": 3, \"ccp_alpha\": 0.01}, {\"max_depth\": 1}]:\n",
    "    pdpilot_output_path = (\n",
    "        output_dir / f\"pdpilot_max_depth_{decision_tree_params['max_depth']}.json\"\n",
    "    )\n",
    "    partial_dependence(\n",
    "        predict=booster.predict,\n",
    "        df=df_X,\n",
    "        features=features,\n",
    "        resolution=resolution,\n",
    "        decision_tree_params=decision_tree_params,\n",
    "        seed=seed,\n",
    "        n_jobs=1,\n",
    "        output_path=pdpilot_output_path.as_posix(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VINE\n",
    "\n",
    "We run VINE with `n_clusters=2`, which is what we think the ICE plot for x2 should have, and with `n_clusters=5`, which is the default value. We do this both with and without `prune_clusters` set, which does additional pruning of the clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_clusters, prune_clusters in [(2, True), (5, True), (2, False), (5, False)]:\n",
    "    vine_output_path = (\n",
    "        output_dir / f\"vine_n_clusters_{num_clusters}_prune_{prune_clusters}.json\"\n",
    "    ).as_posix()\n",
    "\n",
    "    vine.calculate_and_export(\n",
    "        data=df_X,\n",
    "        y=y,\n",
    "        predict_func=booster.predict,\n",
    "        num_clusters=num_clusters,\n",
    "        num_grid_points=resolution,\n",
    "        ice_curves_to_export=num_instances,\n",
    "        cluster_method=\"good\",\n",
    "        prune_clusters=prune_clusters,\n",
    "        seed=seed,\n",
    "        output_path=vine_output_path,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyze the case of 5 clusters in more depth, we also run VINE for 5 clusters without merging clusters with similar explanations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vine_no_merge_output_path = (\n",
    "    output_dir / \"vine_n_clusters_5_prune_False_merge_False.json\"\n",
    ").as_posix()\n",
    "\n",
    "vine.calculate_and_export(\n",
    "    data=df_X,\n",
    "    y=y,\n",
    "    predict_func=booster.predict,\n",
    "    num_clusters=5,\n",
    "    num_grid_points=resolution,\n",
    "    ice_curves_to_export=num_instances,\n",
    "    cluster_method=\"good\",\n",
    "    prune_clusters=False,\n",
    "    merge_clusters=False,\n",
    "    seed=seed,\n",
    "    output_path=vine_no_merge_output_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdpilot-eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
