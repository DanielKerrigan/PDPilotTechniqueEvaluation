{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE = \"trial_labeled_pdps.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape(curve, t):\n",
    "    \"\"\"Get the shape of the curve for the given threshold.\"\"\"\n",
    "\n",
    "    y = np.array(curve[\"y\"])\n",
    "    diff = np.diff(y)\n",
    "    pos = diff[diff > 0].sum()\n",
    "    neg = np.abs(diff[diff < 0].sum())\n",
    "    percent_pos = pos / (pos + neg) if pos + neg != 0 else 0.5\n",
    "\n",
    "    if percent_pos >= (0.5 + t):\n",
    "        return \"increasing\"\n",
    "    elif percent_pos <= (0.5 - t):\n",
    "        return \"decreasing\"\n",
    "    else:\n",
    "        return \"mixed\"\n",
    "\n",
    "\n",
    "def calculate_accuracy(my_labels, heuristic_labels):\n",
    "    \"\"\"Get the heuristic's accuracy for the given threshold\"\"\"\n",
    "\n",
    "    correct = 0\n",
    "\n",
    "    for i, (a, b) in enumerate(zip(my_labels, heuristic_labels)):\n",
    "        if a == b:\n",
    "            correct += 1\n",
    "\n",
    "    return correct / len(my_labels)\n",
    "\n",
    "\n",
    "def get_scores(curves):\n",
    "    \"\"\"Find the threshold in the range [0, 0.5) that gives the best accuracy.\"\"\"\n",
    "\n",
    "    my_labels = [curve[\"shape\"] for curve in curves]\n",
    "\n",
    "    thresholds = np.linspace(0, 0.5, 101)\n",
    "    accuracies = []\n",
    "    labels = []\n",
    "\n",
    "    for t in thresholds:\n",
    "        heuristic_labels = [get_shape(curve, t) for curve in curves]\n",
    "        accuracy = calculate_accuracy(my_labels, heuristic_labels)\n",
    "        accuracies.append(accuracy)\n",
    "        labels.append(heuristic_labels)\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        {\"threshold\": thresholds, \"accuracy\": accuracies, \"labels\": labels}\n",
    "    )\n",
    "\n",
    "\n",
    "def read_json(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as fp:\n",
    "        return json.load(fp)\n",
    "\n",
    "\n",
    "def check_labels(curves, heuristic_labels):\n",
    "    \"\"\"if there are cases where I labeled it increasing and the\n",
    "    heurisitc labels it decreasing, then I likely\n",
    "    made a mistake when labeling.\"\"\"\n",
    "\n",
    "    my_labels = [curve[\"shape\"] for curve in curves]\n",
    "\n",
    "    bad = []\n",
    "\n",
    "    for i, (a, b) in enumerate(zip(heuristic_labels, my_labels)):\n",
    "        if (a == \"increasing\" and b == \"decreasing\") or (\n",
    "            a == \"decreasing\" and b == \"increasing\"\n",
    "        ):\n",
    "            # if this is true, it's likely because I made a mistake when labeling\n",
    "            bad.append(i)\n",
    "            print(f\"curve {i + 1}: my label is {a}, heuristic label is {b}\")\n",
    "\n",
    "    return bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curves = read_json(INPUT_FILE)\n",
    "df = get_scores(curves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df).mark_line().encode(\n",
    "    x=alt.X(\"threshold\").title(\"t\"), y=alt.Y(\"accuracy\").title(\"Accuracy\")\n",
    ").properties(width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = df.iloc[df[\"accuracy\"].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_labels(curves, best[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdpilot-eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
