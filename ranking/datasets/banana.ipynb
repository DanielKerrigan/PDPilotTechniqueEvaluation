{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Banana Dataset\n",
    "\n",
    "- [Link to dataset](https://sci2s.ugr.es/keel/dataset.php?cod=182)\n",
    "- [Link to PMLB](https://epistasislab.github.io/pmlb/profile/banana.html)\n",
    "\n",
    "binary classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from pmlb import fetch_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pdpilot import PDPilotWidget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(df, n, objective):\n",
    "    \"\"\"Stratified sample for binary datasets, random for regression.\"\"\"\n",
    "    if objective == \"binary\":\n",
    "        return train_test_split(\n",
    "            df, train_size=n, random_state=1, stratify=df[\"target\"]\n",
    "        )[0]\n",
    "    else:\n",
    "        return df.sample(n, random_state=1)\n",
    "\n",
    "\n",
    "def load_dataset(dataset_info, datasets_dir):\n",
    "    \"Download the dataset.\"\n",
    "\n",
    "    dataset = dataset_info[\"name\"]\n",
    "    objective = dataset_info[\"objective\"]\n",
    "    exclude_features = dataset_info[\"exclude_features\"]\n",
    "\n",
    "    df_all = fetch_data(dataset_info[\"name\"], local_cache_dir=datasets_dir.as_posix())\n",
    "\n",
    "    df_reduced = (\n",
    "        df_all if df_all.shape[0] <= 200_000 else sample(df_all, 200_000, objective)\n",
    "    )\n",
    "\n",
    "    df_X = df_reduced.drop(columns=[\"target\"] + exclude_features)\n",
    "    y = df_reduced[\"target\"].to_numpy()\n",
    "\n",
    "    # drop columns that only have one unique value\n",
    "    nunique = df_X.nunique()\n",
    "    df_X.drop(columns=nunique[nunique == 1].index, inplace=True)\n",
    "\n",
    "    features = list(df_X.columns)\n",
    "    nominal_features = [f for f in dataset_info[\"nominal_features\"] if f in features]\n",
    "\n",
    "    # convert float columns that contain only integers to integers\n",
    "    for feature in features:\n",
    "        as_int = df_X[feature].astype(int)\n",
    "        if np.array_equal(df_X[feature], as_int):\n",
    "            df_X[feature] = as_int\n",
    "\n",
    "    X = df_X.to_numpy()\n",
    "\n",
    "    return dataset, objective, df_X, X, y, features, nominal_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_group = \"big\"\n",
    "dataset = \"banana\"\n",
    "\n",
    "datasets = json.loads(Path(\"../../data/datasets.json\").read_bytes())\n",
    "datasets_dir = Path(f\"../../data/results/{dataset_group}/datasets\")\n",
    "dataset_info = [ds for ds in datasets[dataset_group] if ds[\"name\"] == dataset][0]\n",
    "\n",
    "booster = lgb.Booster(\n",
    "    model_file=f\"../../data/results/{dataset_group}/models/{dataset}.txt\"\n",
    ")\n",
    "pd_data = Path(f\"../../data/results/{dataset_group}/pdpilot/{dataset}.json\")\n",
    "stuff = json.loads(\n",
    "    Path(f\"../../data/results/{dataset_group}/stuff/{dataset}.json\").read_bytes()\n",
    ")\n",
    "importances = pd.read_csv(\n",
    "    f\"../../data/results/{dataset_group}/importances/{dataset}.csv\"\n",
    ")\n",
    "\n",
    "dataset, objective, df_X, X, y, features, nominal_features = load_dataset(\n",
    "    dataset_info, datasets_dir\n",
    ")\n",
    "\n",
    "df_Xy = df_X.copy()\n",
    "df_Xy[\"target\"] = y\n",
    "\n",
    "df_Xy_sample = df_Xy if df_Xy.shape[0] <= 2000 else sample(df_Xy, 2000, objective)\n",
    "\n",
    "df_pd = df_Xy_sample.drop(columns=[\"target\"])\n",
    "y_pd = df_Xy_sample[\"target\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert list(df_pd.index) == stuff[\"pdpilot_indices\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = PDPilotWidget(\n",
    "    predict=booster.predict, df=df_pd, labels=y_pd, pd_data=pd_data, seed=56, height=650\n",
    ")\n",
    "\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(importances).mark_bar().encode(\n",
    "    y=alt.Y(\"feature\").sort(\"-x\"),\n",
    "    x=alt.X(alt.repeat(\"row\"), type=\"quantitative\"),\n",
    "    fill=alt.Fill(\"feature\").legend(None),\n",
    ").repeat(row=[\"score_ice\", \"score_pdp\", \"score_perm\", \"score_shap\", \"score_lgb\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff[\"cv_results\"][\"mean_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdpilot-eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
